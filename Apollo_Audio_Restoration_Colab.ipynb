{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-_VkjEtMvc5"
   },
   "source": [
    "[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/Q5Q811R5YI)  \n",
    "# Apollo-Colab-Inference [![Open In Github](https://img.shields.io/badge/github-code-green)](https://github.com/jarredou/Apollo-Colab-Inference/)  \n",
    "\n",
    "\n",
    "*Original work [Apollo: Band-sequence Modeling for High-Quality Music Restoration in Compressed Audio](https://github.com/JusperLee/Apollo)*  \n",
    "\n",
    "The model was trained to restore/enhance lossy mp3 audio with bitrate <= 128 kbps.  \n",
    "<br>\n",
    "___  \n",
    "*changelog:*\n",
    "\n",
    "<font size=2>**v0.5**  \n",
    "<font size=2>- added: lew's universal model  \n",
    "\n",
    "<font size=2>**v0.4**  \n",
    "<font size=2>- added: config loader  \n",
    "<font size=2>- added: lew's separated vocals enhancer v2 beta\n",
    "\n",
    "<font size=2>**v0.3**  \n",
    "<font size=2>- lew's separated vocals enhancer model added\n",
    "\n",
    "<font size=2>**v0.2**  \n",
    "<font size=2>- added overlap feature  \n",
    "<font size=2>- new inference.py created for easier local CLI use  \n",
    "\n",
    "<font size=2>**v0.1**  \n",
    "<font size=2>- added chunking for long audio inputs  \n",
    "<font size=2>- ~~added \"dual mono\" processing for stereo audio input (processing each channel independently)~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "8NuwnC--VPO4"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "#@markdown #Install\n",
    "%cd /content/\n",
    "!git clone https://github.com/SUC-DriverOld/Apollo-Training.git && cd Apollo-Training\n",
    "\n",
    "!rm -rf '/content/Apollo-Training/inference.py'\n",
    "%cd /content/Apollo-Training\n",
    "!wget 'https://raw.githubusercontent.com/Qupci/Apollo-Colab-Inference/main/inference.py'\n",
    "\n",
    "!pip install omegaconf ml_collections\n",
    "\n",
    "!yes | pip uninstall -y torch torchvision torchaudio\n",
    "!yes | pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "xFqIYcKxVXyd"
   },
   "outputs": [],
   "source": [
    "%cd /content/Apollo-Training\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    \"\"\"Download a file using wget via subprocess and save to save_path.\n",
    "    Uses -c to continue partial downloads and -O to specify output path.\n",
    "    Raises RuntimeError if wget exits with non-zero code.\"\"\"\n",
    "    # Ensure parent directory exists\n",
    "    os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True)\n",
    "    cmd = [\"wget\", \"-c\", \"--show-progress\", \"-O\", save_path, url]\n",
    "    proc = subprocess.run(cmd)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f\"wget failed with exit code {proc.returncode} for url {url}\")\n",
    "    print(f\"Descargado: {save_path}\")\n",
    "\n",
    "models_folder = '/content/Apollo-Training/model'\n",
    "configs_folder = '/content/Apollo-Training/configs'\n",
    "# Ensure model and config folders exist before attempting downloads\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "os.makedirs(configs_folder, exist_ok=True)\n",
    "\n",
    "#@markdown #Inference\n",
    "#@markdown For the universal model set *chunk_size* above to 19, for all other models set it to 25\n",
    "input_folder_path = '/content/drive/MyDrive/input' #@param {type:\"string\"}\n",
    "output_folder_path = '/content/drive/MyDrive/output' #@param {type:\"string\"}\n",
    "model = 'Baicai1145 Vocal MSST' #@param ['MP3 Enhancer', 'Lew Vocal Enhancer', 'Lew Vocal Enhancer v2 (beta)', 'Lew Universal Lossy Enhancer', 'Baicai1145 Vocal MSST']\n",
    "chunk_size = 25 #@param {type:\"slider\", min:3, max:25, step:1}\n",
    "overlap = 2 #@param {type:\"slider\", min:2, max:10, step:1}\n",
    "\n",
    "if model == 'MP3 Enhancer':\n",
    "    # URL from the install cell (was previously fetched with wget)\n",
    "    model_url = \"https://huggingface.co/JusperLee/Apollo/resolve/main/pytorch_model.bin\"\n",
    "    model_filename = \"pytorch_model.bin\"\n",
    "    download_file(model_url, os.path.join(models_folder, model_filename))\n",
    "    ckpt = os.path.join(models_folder, model_filename)\n",
    "    config = 'configs/apollo.yaml'\n",
    "if model == 'Lew Vocal Enhancer':\n",
    "    model_url = \"https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model.ckpt\"\n",
    "    config_url = \"https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/config_apollo_vocal.yaml\"\n",
    "    model_filename = \"apollo_model.ckpt\"\n",
    "    config_filename = \"config_apollo_vocal.yaml\"\n",
    "    download_file(model_url, os.path.join(models_folder, model_filename))\n",
    "    download_file(config_url, os.path.join(configs_folder, config_filename))\n",
    "    ckpt = os.path.join(models_folder, model_filename)\n",
    "    config = os.path.join(configs_folder, config_filename)\n",
    "if model == 'Lew Vocal Enhancer v2 (beta)':\n",
    "    model_url = \"https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model_v2.ckpt\"\n",
    "    config_url = \"https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/config_apollo_vocal.yaml\"\n",
    "    model_filename = \"apollo_model_v2.ckpt\"\n",
    "    config_filename = \"config_apollo_vocal.yaml\"\n",
    "    download_file(model_url, os.path.join(models_folder, model_filename))\n",
    "    download_file(config_url, os.path.join(configs_folder, config_filename))\n",
    "    ckpt = os.path.join(models_folder, model_filename)\n",
    "    config = os.path.join(configs_folder, config_filename)\n",
    "if model == 'Lew Universal Lossy Enhancer':\n",
    "    model_url = \"https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/apollo_model_uni.ckpt\"\n",
    "    config_url = \"https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/config_apollo_uni.yaml\"\n",
    "    model_filename = \"apollo_model_uni.ckpt\"\n",
    "    config_filename = \"config_apollo_uni.yaml\"\n",
    "    download_file(model_url, os.path.join(models_folder, model_filename))\n",
    "    download_file(config_url, os.path.join(configs_folder, config_filename))\n",
    "    ckpt = os.path.join(models_folder, model_filename)\n",
    "    config = os.path.join(configs_folder, config_filename)\n",
    "if model == 'Baicai1145 Vocal MSST':\n",
    "    model_url = \"https://huggingface.co/baicai1145/Apollo-vocal-msst/resolve/main/model_apollo_vocals_ep_54.ckpt\"\n",
    "    config_url = \"https://huggingface.co/baicai1145/Apollo-vocal-msst/resolve/main/config_apollo_vocals_ep_54.yaml\"\n",
    "    model_filename = \"model_apollo_vocals_ep_54.ckpt\"\n",
    "    config_filename = \"config_apollo_vocals_ep_54.yaml\"\n",
    "    download_file(model_url, os.path.join(models_folder, model_filename))\n",
    "    download_file(config_url, os.path.join(configs_folder, config_filename))\n",
    "    ckpt = os.path.join(models_folder, model_filename)\n",
    "    config = os.path.join(configs_folder, config_filename)\n",
    "\n",
    "# Get list of input files\n",
    "input_files = [os.path.join(input_folder_path, f) for f in os.listdir(input_folder_path)]\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Process each input file\n",
    "for input_file in input_files:\n",
    "    filename, file_extension = os.path.splitext(os.path.basename(input_file))\n",
    "    output_file = os.path.join(output_folder_path, f\"{filename}.wav\")\n",
    "    !python inference.py \\\n",
    "        --in_wav '{input_file}' \\\n",
    "        --out_wav '{output_file}' \\\n",
    "        --chunk_size {chunk_size} \\\n",
    "        --overlap {overlap} \\\n",
    "        --ckpt '{ckpt}' \\\n",
    "        --config '{config}'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
